---
title: "Zero-inflated Poisson distribution with upper bounds"
author: "Aurimas Racas"
date: '2022-11-05'
output: html_document
---

```{r setup, include=FALSE, echo=F}
library(tidyverse)
library(broom)
library(extraDistr)
library(pscl)
library(ggplot2)
library(ggridges)
library(gridExtra)
library(ggtext)
library(parallel)
library(kableExtra)
options('mc.cores' = 6)
library(pbapply)
library(rBayesianOptimization)

```


# Generating samples

```{r samples, echo=F}
n = 3000

set.seed(42)
#sample from zero-inflated truncated poisson distribution
# p: probability of success (bernoulli)
# lambda: mean of poisson distribution
# upper_limit: upper bound of poisson distribution
generate_sample = function(n, p, lambda, upper_limit) {
  obs = rbinom(n, 1, 1 - p)
  cnt_non_zero = length(obs[obs == 1])
  obs[obs == 1] = rtpois(cnt_non_zero, lambda, b=upper_limit)
  obs
}


#generate a tibble that saves sampling configuration parameters, too
generate_tibble = function(name, n, p, lambda, upper_limit) {
  s = generate_sample(n, p, lambda, upper_limit)
  tibble(
    count = s,
    group = name,
    n = n,
    p = p,
    lambda = lambda,
    upper_limit = upper_limit
  )
}

joint_dt = bind_rows(
  generate_tibble("control", n, p = 0.3, lambda = 4, upper_limit = 7),
  generate_tibble("treatment1", n, p = 0.25, lambda = 4, upper_limit = 7),
  generate_tibble("treatment2", n, p = 0.3, lambda = 4.5, upper_limit = 7),
  generate_tibble("treatment3", n, p = 0.38, lambda = 4.5, upper_limit = 7),
)


```

# Basic ZIP histogram

```{r}
generate_tibble("control", n, p = 0.3, lambda = 4, upper_limit = 7) %>%
  ggplot(aes(x=count)) + geom_histogram(bins=15) + xlab("") +
  ylab("# of users") +
  ggtitle("# of days users did something on the app during a week") +
  theme_bw() +
  theme(
    plot.subtitle = element_markdown(),
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank()
  )

ggsave("images/Basic ZIP histogram.png", width=7, height=5)
```

# Creating hypothetical treatment and control groups

```{r summary_stats, fig.width=15, fig.height=5}
joint_dt['success'] = (joint_dt$count > 2) * 1

summary_stats = joint_dt %>% group_by(group, p, lambda, n) %>% 
  summarize(
    success_rate = mean(success),
    sample_mean = mean(count),
    sample_var = var(count),
    .groups='drop'
  ) %>% 
  rename(λ = lambda, π=p)

treatments = c('treatment1', 'treatment2', 'treatment3')

charts = lapply(
  c('treatment1', 'treatment2', 'treatment3'), 
  function(treatment) {
    
    control_stats = summary_stats %>% 
      filter(group == 'control') %>% slice(1)
    
    treatment_stats = summary_stats %>% 
      filter(group == treatment) %>% slice(1)
    
    placeholder_text = "**[N]** \n \n λ=[L]; π=[P]; x̄=[M]; σ=[V]; success rate=[S];" 
    
    
    control_text = str_replace_all(
      placeholder_text,
      fixed(c(
        "[N]" = "Control",
        "[L]" = format(control_stats[['lambda']]),
        "[P]" = format(control_stats[['p']]),
        "[M]" = format(round(control_stats[['sample_mean']], 2)),
        "[V]" = format(round(sqrt(control_stats[['sample_var']]),2)),
        "[S]" = format(round(control_stats[['success_rate']],4) * 100, nsmall=2)
      ))
    )
    
    tr_text = str_replace_all(
      placeholder_text,
      fixed(c(
        "[N]" = treatment_stats[['group']],
        "[L]" = format(treatment_stats[['lambda']]),
        "[P]" = format(treatment_stats[['p']]),
        "[M]" = format(round(treatment_stats[['sample_mean']], 2)),
        "[V]" = format(round(sqrt(treatment_stats[['sample_var']]),2)),
        "[S]" = format(round(treatment_stats[['success_rate']],4) * 100, nsmall=2)
      ))
    )
      
    
    
    subtitle = paste0(control_text, "\n \n", tr_text)
    
    ggplot(
      data = joint_dt %>% filter(group %in% c('control', treatment)), 
      mapping = aes(x=count, color=group, fill=group)
    ) + 
    geom_histogram(alpha=1, position='dodge', bins=15) +
    #geom_density(alpha=0.3) +
    xlab("") +
    ggtitle("", subtitle = subtitle) + 
    theme_bw() +
    theme(
      plot.subtitle = element_markdown(),
      panel.grid.major = element_blank(), 
      panel.grid.minor = element_blank()
      )
    
  })


c = grid.arrange(arrangeGrob(grobs=charts, ncol=3))
ggsave("images/density_illustration.png", c, width=21, height=7)

```

```{r}
summary_stats %>% kbl(digits=c(NA,2,1,0,3,2,2)) %>% 
  kable_classic_2(full_width = F)
```


# Setting up functions to do testing


```{r model_fit, fig.width=15, fig.height=5}
## proportion test
test_proportions = function(dt, level = 0.99) {
  model = glm(success ~ group, data=dt, family=binomial)
  cis = confint(model, level = level)
  colnames(cis) = c('lower', 'upper')
  
  zero_intercept_value = model$coefficients[[1]]
  base_prob = exp(zero_intercept_value) / (1 + exp(zero_intercept_value))
  
  tidy(model) %>% 
    mutate(test = 'proportions') %>% 
    bind_cols(cis %>% as_tibble()) %>%
    mutate(
      effect = exp(
        {{zero_intercept_value}} + estimate
        ) / (
          1 + exp({{zero_intercept_value}} + estimate)
        ) - base_prob, 
      
      lower = exp(
        {{zero_intercept_value}} + lower
        ) / (
          1 + exp({{zero_intercept_value}} + lower)
        ) - base_prob,
      
      upper = exp(
        {{zero_intercept_value}} + upper
        ) / (
          1 + exp({{zero_intercept_value}} + upper)
        ) - base_prob
    ) %>%
    select(-statistic, -std.error, -estimate)
    
}

#test normal
test_normal = function(dt, level = 0.99) {
  model = lm(count ~ group, data=dt)
  cis = confint(model, level = level)
  colnames(cis) = c('lower', 'upper')
  
  tidy(model) %>% 
    mutate(test = 'normal') %>% 
    mutate(effect = estimate) %>%
    select(-statistic, -std.error, -estimate) %>%
    bind_cols(cis %>% as_tibble())
}

#test pois 
test_pois = function(dt, level = 0.99) {
  model = glm(count ~ group, data=dt, family=poisson)
  intercept_value = model$coefficients[[1]]
  cis = confint(model, level = level)
  colnames(cis) = c('lower', 'upper')
  
  tidy(model) %>% 
    mutate(test = 'poisson') %>% 
    bind_cols(cis %>% as_tibble()) %>% 
    mutate(
      effect = exp({{intercept_value}})*(exp(estimate) - 1),
      lower = exp({{intercept_value}})*(exp(lower) - 1),
      upper = exp({{intercept_value}})*(exp(upper) - 1)
    ) %>%
    select(-statistic, -std.error, -estimate)
}

#test zero-inf 
test_zeroinfl = function(dt, level = 0.99) {
  model = zeroinfl(count ~ group, data=dt)
  
  estimates = 
    model$coefficients$count %>% 
    as_tibble(rownames='term') %>%
    mutate(test = 'zeroinfl-count') %>% 
    bind_rows(
      model$coefficients$zero %>% 
        as_tibble(rownames='term') %>%
        mutate(test = 'zeroinfl-zero')
    ) %>% rename(estimate = value)
  
  summ = summary(model)
  
  pvalues = summ$coefficients$count[,4] %>% 
    as_tibble(rownames='term') %>%
    mutate(test = 'zeroinfl-count') %>% 
    bind_rows(
      summ$coefficients$zero[,4] %>% 
        as_tibble(rownames='term') %>%
        mutate(test = 'zeroinfl-zero')
    ) %>% rename(p.value = value)
  
  
  cis = confint(model, level = level)
  colnames(cis) = c('lower', 'upper') 
  
  clean_cis = cis %>% 
    as_tibble(rownames = 'grouping') %>%
    mutate(test = paste0('zeroinfl-', str_split_fixed(grouping, "_", 2)[,1])) %>%
    mutate(term = str_split_fixed(grouping, "_", 2)[,2])
  
  count_intercept_value = model$coefficients$count[[1]]
  
  results = estimates %>% 
    inner_join(pvalues, by=c('test', 'term')) %>%
    inner_join(clean_cis, by=c('test', 'term')) 
  
  count_results = results %>% filter(test == 'zeroinfl-count') %>%
    mutate(
      effect = exp({{count_intercept_value}})*(exp(estimate) - 1),
      lower = exp({{count_intercept_value}})*(exp(lower) - 1),
      upper = exp({{count_intercept_value}})*(exp(upper) - 1)
    )
  
  zero_intercept_value = model$coefficients$zero[[1]]
  base_prob = exp(zero_intercept_value) / (1 + exp(zero_intercept_value))
  
  zero_results = results %>% filter(test == 'zeroinfl-zero') %>%
    mutate(
      effect = exp(
        {{zero_intercept_value}} + estimate
        ) / (
          1 + exp({{zero_intercept_value}} + estimate)
        ) - base_prob, 
      
      lower = exp(
        {{zero_intercept_value}} + lower
        ) / (
          1 + exp({{zero_intercept_value}} + lower)
        ) - base_prob,
      
      upper = exp(
        {{zero_intercept_value}} + upper
        ) / (
          1 + exp({{zero_intercept_value}} + upper)
        ) - base_prob
    )

  bind_rows(zero_results, count_results) %>%
    select(-grouping, -estimate)
  
}


```

## Visualizing test results

```{r}


results = bind_rows(
  test_proportions(joint_dt, level=0.95),
  test_normal(joint_dt, level=0.95),
  test_pois(joint_dt, level=0.95)
)


plot_results = function(df, level=0.99) {
  df %>% 
  filter(term != "(Intercept)") %>%
  mutate(significance = if_else(p.value < 1 - level, "p < 0.05", "p > 0.05")) %>%
  mutate(term = str_replace(term, "group", "")) %>%
  mutate(term = str_replace_all(
    term, 
    c('treatment1', 'treatment2', 'treatment3'), 
    c('Treatment 1: \n π + 0.05', 'Treatment 2: \n λ + 0.5', 'Treatment 3: \n π + 0.08; λ + 0.5')
  )) %>%
  ggplot() + 
    geom_hline(yintercept = 0, linetype='dotted') + 
  geom_point(aes(x=term, y=effect, color=significance)) + 
  geom_text(
    aes(
      x=term, 
      y=effect, 
      label=format(round(effect,3), digits=1), 
      color=significance
    ),
    hjust=-0.2, 
    size=3) + 
  geom_errorbar(aes(x=term, ymin=lower, ymax=upper, color=significance)) + 
  facet_wrap(~test, nrow=1) + ylab("effect on linear scale") +
  xlab('') + theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
}



plot_results(results, level=0.95)
ggsave('images/recovered_coefficients_missp.png', width=12, height=4)


test_zeroinfl(joint_dt, level=0.95) %>%
  mutate(test = str_replace(test, "-zero", " π")) %>%
  mutate(test = str_replace(test, "-count", " λ")) %>%
  plot_results(level=0.95)

ggsave('images/recovered_coefficients_zipf.png', width=12, height=4)
```


# Power Analysis

## Illustrative example

```{r}

set.seed(42*42)

#computes power via a simulation
#arguments:
# n - sample size in group
# x_generator - callable to generate control sample
# y_generator - callable to generate treatment sample
# eval_func - callable that should return if test was significant
# iterations - number of simulation iterations
compute_power = function(n, x_generator, y_generator, eval_func, iterations) {
  r = pblapply(1:iterations, function(i) {
    x = x_generator(n)
    y = y_generator(n)
    eval_func(x,y)
  }, cl=6)
  mean(simplify2array(r))
}

#function that returns boolean if t.test was significant at 0.05 level
t_test = function(c, t) {
  t.test(x=c, y=t, conf.level=0.95, var.equal = F)$p.value < 0.05
}


#compute power for means difference of 0.1 with standard deviation of 2.4
computed_t_test_power = compute_power(
  n = 1000,
  x_generator = function(n) rnorm(n, 0, 2.4),
  y_generator = function(n) rnorm(n, 0.1, 2.4),
  eval_func = t_test,
  iterations = 10000
)


actual_t_test_power = power.t.test(
  n=1000, 
  delta=0.1, 
  sd=2.4, 
  sig.level = 0.05
)$power

print(paste(
  "Computed power:", 
  format(computed_t_test_power, digits=4), 
  "vs. actual power:", 
  format(actual_t_test_power, digits=4)
))

```
## Setting up functions to return whether a test was significant

```{r}

pois_test = function(x,y) {
  r = glm(c ~ group, family=poisson, data = bind_rows(
    tibble(c=x, group='control'),
    tibble(c=y, group='test')
  )) %>% tidy() 
  
  r$p.value[2] < 0.05
}

prop_test = function(x, y) {
  x_success = sum(x > 2)
  y_success = sum(y > 2)
  prop.test(
    x=c(x_success, y_success), 
    n=c(length(x), length(y)), 
    conf.level = 0.95
  )$p.value < 0.05
}

zipf_test = function(x, y, truth = 'count') {
  m = summary(zeroinfl(c ~ group, data = bind_rows(
    tibble(c=x, group='control'),
    tibble(c=y, group='test')
  )))
  p_count = m$coefficients$count[2,4]
  p_zero = m$coefficients$zero[2,4]
  if (truth == 'count') return(p_count < 0.05)
  if (truth == 'zero') return(p_zero < 0.05)
  if (truth == 'both') return((p_zero < 0.05) & (p_count < 0.05))
}

```

## Running power analysis for n=3000

```{r}

set.seed(42*42)

control_generator = function(n) generate_sample(n, 0.3, 4.0, 7)

treatment_generators = c(
  'treatment1' = function(n) generate_sample(n, 0.25, 4, 7),
  'treatment2' = function(n) generate_sample(n, 0.3, 4.5, 7), 
  'treatment3' = function(n) generate_sample(n, 0.38, 4.5, 7)
)

tests = c(
  'normal' = t_test,
  'poisson' = pois_test,
  'zipf' = zipf_test,
  'proportions' = prop_test
)

zip_params = list(
  'treatment1' = 'zero', 
  'treatment2' = 'count', 
  'treatment3' = 'both'
)


iterations = 1000

power_levels = mapply(function(tr_generator, tr_name) {
  results <- pblapply(1:iterations, function(i) {
    control <- control_generator(n)
    treatment <- tr_generator(n)
    mapply(function(test, name) {
      if (name != 'zipf') return(test(control, treatment))
      return(test(control, treatment, truth=zip_params[[tr_name]]))
    }, tests, names(tests))
  }, cl=6)
  
  r <- simplify2array(results)
  apply(r, 1, mean)
}, treatment_generators, names(treatment_generators))

power_results = power_levels %>% as_tibble(rownames = 'test') %>%
  pivot_longer(
    cols=c('treatment1', 'treatment2', 'treatment3'), 
    names_to = 'group', 
    values_to = 'power'
  ) %>% mutate(source = 'simulated') %>%
  mutate(group = str_replace_all(
    group, 
    c('treatment1', 'treatment2', 'treatment3'), 
    c('treatment: π + 0.05', 'treatment: λ + 0.5', 'treatment: π + 0.08; λ + 0.5')
  ))


```

## Running power analysis based on large-sample approximation

```{r, power_comparisons, fig.width=7, fig.height=4}
n_large = 1000000
n = 3000

theoretical_powers = mapply(function(tr_generator, tr_name) {
  control = control_generator(n_large)
  treatment = tr_generator(n_large)
  
  prop_x = mean(control > 2)
  prop_y = mean(treatment > 2)
  
  delta = mean(control) - mean(treatment)
  st_dev = sd(control)
  
  c(
    'proportions' = power.prop.test(
      n=n, 
      p1=prop_x, 
      p2=prop_y, 
      sig.level = 0.05
    )$power,
    
    'normal' = power.t.test(
      n=n, 
      delta=delta, 
      sd=st_dev, 
      sig.level = 0.05
    )$power
  )
    
}, treatment_generators, names(treatment_generators))

th_results = theoretical_powers %>% as_tibble(rownames='test') %>%
  pivot_longer(
    cols=c('treatment1', 'treatment2', 'treatment3'), 
    names_to = 'group', 
    values_to = 'power'
  ) %>% mutate(source = 'large-n-approximation') %>%
  mutate(group = str_replace_all(
    group, 
    c('treatment1', 'treatment2', 'treatment3'), 
    c('treatment: π + 0.05', 'treatment: λ + 0.5', 'treatment: π + 0.08; λ + 0.5')
  ))

th_results

```

## Visualizing results

```{r}
ggplot(power_results, aes(x=group, y=power, color=test, fill=test)) + 
  geom_col(position=position_dodge2()) + 
  geom_text(aes(label=format(power, digits=3, nsmall=2), group=test, y= power - 0.05),
    position=position_dodge2(0.9), color='white', size=3
  ) +
  xlab("Treatment") + ylab("Power") +
  theme_bw() +
  theme(
    panel.grid.major.x = element_blank(), 
    panel.grid.minor.x = element_blank()
  ) + ggtitle("Power comparisons at N=3000")


ggsave('images/power_comparisons.png', width=7, height=4)
```
```{r comp_powers, fig.height=5, fig.width=10}
bind_rows(th_results, power_results) %>% 
  filter(test %in% c('normal', 'proportions')) %>%
ggplot() +
  geom_point(aes(x=test, y=power, color=source)) +
  facet_wrap(~group) +
  xlab("Test") + ylab("Power") +
  theme_bw() +
  theme(
    panel.grid.major.x = element_blank(), 
    panel.grid.minor.x = element_blank()
  ) + ggtitle("Power estimated via simulation vs. computed via large sample")

ggsave("images/Simulated vs. actual power compared.png", width=10, height=5)
```



## Running power analysis at different N sizes

```{r}

iterations = 1000
n_sequence = seq(from=500, to=3000, by=100)

powers_accross_n = pblapply(n_sequence, function(n) {
  powers = mapply(function(tr_generator, tr_name) {
    results <- mclapply(1:iterations, function(i) {
      control <- control_generator(n)
      treatment <- tr_generator(n)
      mapply(function(test, name) {
        if (name != 'zipf') return(test(control, treatment))
        return(test(control, treatment, truth=zip_params[[tr_name]]))
      }, tests, names(tests))
    }, mc.cores=6)
    
    r <- simplify2array(results)
    apply(r, 1, mean)
  }, treatment_generators, names(treatment_generators))
  
  as_tibble(powers, rownames = 'test') %>% mutate(n = n)
  
})

```
## Visualizing results

```{r viz_n, fig.height=5, fig.width=15}
power_df = do.call(bind_rows, powers_accross_n) %>% 
  pivot_longer(
    cols=c('treatment1', 'treatment2', 'treatment3'), 
    names_to = 'group', 
    values_to = 'power'
  ) %>% 
  mutate(group = str_replace_all(
    group, 
    c('treatment1', 'treatment2', 'treatment3'), 
    c('treatment: π + 0.05', 'treatment: λ + 0.5', 'treatment: π + 0.08; λ + 0.5')
  ))

ggplot(power_df, mapping=aes(x=n, y=power, color=test, fill=test)) + 
  geom_point() + geom_line() + facet_wrap(~group, ncol=3) + 
  xlab("Sample size") + ylab("Power") +
  geom_abline(slope=0, intercept=0.8, linetype='dashed', size=0.2) +
  theme_bw() +
  theme(
    panel.grid.major.y = element_blank(), 
    panel.grid.minor.y = element_blank()
  ) + ggtitle("Power comparisons at different sample sizes") +
  scale_x_continuous(breaks = seq(500,3000,500))

ggsave("images/power_at_different_n.png", width=15, height=5)
```

## Using Bayesian optimization to find required sample size

```{r}
library(rBayesianOptimization)

#zip test 
zipf_test = function(x, y, truth = 'count') {
  m = summary(zeroinfl(c ~ group, data = bind_rows(
    tibble(c=x, group='control'),
    tibble(c=y, group='test')
  )))
  p_count = m$coefficients$count[2,4]
  p_zero = m$coefficients$zero[2,4]
  if (truth == 'count') return(p_count < 0.05)
  if (truth == 'zero') return(p_zero < 0.05)
  if (truth == 'both') return((p_zero < 0.05) & (p_count < 0.05))
}

#functions to generate samples from control/treatment 
# that differ by #minimum detectable effect
control_generator = function(n) generate_sample(n, 0.3, 4.0, 7)
treatment_generator = function(n) generate_sample(n, 0.38, 4.5, 7)

#loss function that takes sample size n
# and returns a "loss" computed based on the difference between 
# power level at sample size n and the target power level
loss_func = function(n, power, no_iter) {
  est_power = compute_power(
    n=floor(n),
    x_generator = control_generator,
    y_generator = treatment_generator,
    eval_func = function(x,y) zipf_test(x, y, truth='both'),
    iterations = no_iter
  )
  list(Score = -(((power - est_power) * 10) ** 2), Pred=est_power) 
}

# run the bayesian optimization algorithm
bo_res = BayesianOptimization(
  FUN= function(n) loss_func(n, power=0.9, no_iter = 1000), 
  bounds=list(n=c(300, 1500)), #set bounds based on intuition / prior knowledge
  init_points = 3, # let algorithm explore a few points at first
  n_iter = 5, #set a number of max iterations allowed
  eps = 0.1, #set eps to be higher to encourage exploration
  acq='ei' #use expected improvement criteria
)

print(paste(
  "At sample size", bo_res$Best_Par,
  "estimated power level is ", 0.9 - (sqrt(-bo_res$Best_Value) / 10)
))


```